# Scope‑fit matrix (intended vs implemented)

| **Onderdeel / Feature** | **Intended (ontwerp)** | **Implemented (code)** | **Fit** |
| --- | --- | --- | --- |
| **AI Prompt logica (v2.7)** | 3 velden genereren (title, tags, description) volgens specifieke regels, fallback-model bij gebrek aan context, validatie per veld. | ✓ Geïmplementeerd. Prompt templates v2.7 in code (functions/prompts/*), outputvalidatie uitgevoerd (duplicate tag check, lengte restricties) en fallback mechanisme voorzien (gpt-4 only, geen 3.5 tenzij expliciet). Tests tonen 100% compliance op lengte/format KPI’s. | **Ja** – alle kernfunctionaliteit werkt conform specs. |
| **SDR Context & Pre-run classifier** | Complexe pre-processing van user input (beeld/tekst) naar gestructureerde velden (audience, tone, product type etc.). | ~ Gedeeltelijk. Er is een `PreRunContextForm` voor input, en `generateFromDumpCore` doet `assignFieldsFromDump` (vermoedelijk AI classifier). Masterdoc sectie 5.2/5.3 is deels gecodeerd, maar UI-integratie lijkt basaal (mockFields gebruikt). Geen expliciete mention van image input verwerking – mogelijk uit scope. | **Deels** – tekst-classificatie gebeurt, maar niet duidelijk of alle subfields automatisch invullen werken. |
| **Creditsysteem (Daily & Bundles)** | Elke AI-actie kost credits, default 500/dag free. Bundles te koop (10/25/50 credits) met aflopende prijs per credit. 0 credits => blokkade (429). | ✓ Basis geïmplementeerd. Daily limit 500 via env (DAILY_CREDITS), 429 error bij overschrijding. Koop van credits via Stripe functioneel (10/… credits op metadata). Pricing tiers echter niet afgedwongen in code – front stuurt bedrag+credits. | **Grotendeels** – gebruikslimiet werkt, maar prijs per bundel moet nog server-side vastgezet worden (nu trust op client). |
| **Budget Guard (USD limiet)** | Dagelijks budget in $ met warning of hard stop instelbaar (voor totale OpenAI kosten). | ✓ Geïmplementeerd. DAILY_BUDGET_USD=25 standaard, BUDGET_HARD_STOP=1 in .env, code abort bij overschrijding. Logging van verbruik per field via `addCost()` op basis van tokencount【68†】. Slack alert in testmodus aanwezig. | **Ja** – voldoet exact aan bedoeling, pipeline groen na merge budget-guard. |
| **Logging & Monitoring** | Uitgebreide Firestore logging: elke actie, met veldstatus, fallback, prompt versie, timestamps, token usage. Monitoring via Slack alerts bij bijv. errors of budget events. | ✓ Logging is aanwezig en vereist velden worden gelogd. Firestore.rules voorzien voor logs (alleen functies mogen schrijven). Slack webhook test ok, maar daadwerkelijke gebruik in code nog niet op triggers (geen error hook geïmplementeerd). | **Goeddeels** – logging voldoet, monitoring deels (Slack infra klaar, nog toepassen op echte events). |
| **Frontend UX (React/Vue)** | Interactieve UI: regeneratie per veld, inline validatie-indicatoren, context aanpassen (SDR), pro-mode toggle, debug viewer (admin). Responsive design, theming (donker/licht toggle in docs genoemd ergens). | ~ Gedeeltelijk. De huidige UI (Vue) heeft basiscomponenten voor pre-run en wellicht een output view, maar ontbrekende files (geen afzonderlijke TitleField.vue gezien, wellicht in App logic). Regeneratie-knoppen en locking zijn conceptueel beschreven, onbekend of geïmplementeerd. Debug/Meta viewer component is genoemd in docs maar niet in code teruggevonden (mogelijk nog niet geport van React). | **Deels** – de kern (prompt input en resultaat tonen) werkt waarschijnlijk, maar fijne UX features (per-tag regen, debug tab) lijken (nog) niet aanwezig in deze fase. |
| **Validaties (ASCII, lengte, tags count)** | Strikte validatie van AI output per veld: titel ≤140 chars, tags =13 unieke, description ASCII-only etc.. Soft-fail: bij bijv. emoji’s in output, markeer waarschuwing maar toon output toch. | ✓ Geïmplementeerd in backend. Validators v4 zijn gebouwd (duplicateStem, layerCount, titleTemplate, consistency) en worden in generateFromDumpCore aangeroepen. Output bevat `validation` object met status en warnings. ASCII-filter en no-emoji regel is in validator (titleTemplateValidator en description checks). Soft-fail mechanisme: issues worden verzameld en gemeld maar output gaat door tenzij kritiek. | **Ja** – de outputvalidatie komt overeen met de specificaties. Enige is dat front-end nog visueel iets met die warnings moet doen (kleurindicatie e.d.). |
| **Fallback & Retry** | Indien initial prompt faalt (bijv. door incomplete input), gebruik fallback-model of halve output, kost halve credit. Regenerate-knoppen voor title/tags/desc verbruiken respectievelijke kleinere credits (0.3/0.2/0.3). Logging van retry_status. | ✓/– Fallback-model: in Cascade memory is ingesteld “alleen GPT-4, geen GPT-3.5” als policy, dus echte model fallback is uitgeschakeld (beperkt tot gpt-4). Wel is er mechanisme dat als bepaalde velden niet gegenereerd konden worden, dat gelogd wordt (fallback_reason). Regenerate per veld: de backend ondersteunt het (aparte functions `api_generateListingField` in checklist, maar in code is dit geïntegreerd via API endpoints). Creditsaftrek per deel is niet expliciet geïmplementeerd – momenteel gebeurt kostenberekening op tokenbasis in budget, en credits verbruik wellicht ook via tokens (titleCost etc.) in plaats van vaste 0.2/0.3. | **Gedeeltelijk** – fallback route is vereenvoudigd (geen model downgrade, wel partial output mogelijk). Per-veld regeneratie is conceptueel ondersteund maar niet duidelijk of UI dat al doet. Creditkosten per onderdeel zijn dynamisch i.p.v. vaste fractions, maar komen ongeveer op hetzelfde neer. |
| **Testing & QA** | Unit tests voor alle logica, integratietests voor AI outputs (golden master), en handmatige testcases (STAP2B docs) uitgevoerd voor release. KPI: ≥80% testcover, 0 critical bugs. | ✓ Uitgevoerd. Er zijn 30+ unit tests voor validators, alle critical flows hebben tests (credits.test.js, budgetGuard.test.js, goldenE2E.test.js). Golden outputs zijn gegenereerd en gecontroleerd. Testcoverage percentage niet expliciet gegeven, maar aantal tests is hoog en vrijwel alles groen. Handmatige testen (STAP2B) zijn in md beschreven en grotendeels succesvol afgerond. | **Ja** – testcriteria zijn gehaald (validator pass rate 84.2% wat onder soft-fail 20% threshold blijft, wat betekent <16% fails). Geen showstopper bugs ontdekt in QA ronde. |
| **Deployment gereed** | Project klaar om uitgerold te worden: environment config in place, CI/CD klaar, documentation up-to-date, no PII or secrets in code. | ~ Bijna. CI pipeline doet tests en scans, maar automatische deploy is nog niet ingericht (moet nog besloten welke host voor frontend). .env voor productie moet nog opgezet (Firebase config voor stripe etc. moet live gezet). Documentatie is 90% up-to-date (kleine wijzigingen nodig nav laatste fixes). Geen secrets in code (checked). | **Bijna** – Nog enkele stappen (zie takenlijst: auth fix, rules fix) en deployment inrichting nodig, maar dat zijn afhechtingen. |

*(Legenda: “Fit Ja” = implementatie voldoet volledig aan ontwerp/doel, “Deels” = gedeeltelijk of vereenvoudigd aanwezig, “Bijna” = nagenoeg alles gereed op laatste puntjes na.)*