# Assumpties & Onzekerheden

- **Aanname:** De in `.env` aangetroffen API keys (OpenAI beginnend met `sk-proj-...` en de Slack webhook URL) zijn placeholders of testkeys, niet actieve productiegeheimen. We nemen dit aan omdat secret-scans groen waren en “geneutraliseerd” aangeven. **Onzekerheid:** Is bevestigd dat deze keys gedeactiveerd of dummy zijn? *Benodigd bewijs:* Bevestiging door ontwikkelaar of test met die sleutel (wat uiteraard niet is uitgevoerd in deze audit).
- **Aanname:** Gebruikers zullen moeten inloggen (via Firebase Auth of anders) voordat ze het AI-hulpmiddel kunnen gebruiken, zodat het creditsysteem per user werkt. Echter, de huidige UI-code bevat geen expliciete login-component. **Onzekerheid:** Wordt in de praktijk een gesloten gebruikersgroep verondersteld, of is login wel gepland maar nog niet gecommit? *Benodigd:* Duidelijke eisen van product owner: Moet elke gebruiker zich authentiseren of is een gastmodus gewenst? Zo ja, dan moet dat technisch nog ingebouwd.
- **Onzekerheid:** De vue-frontend is vrij minimalistisch in de zip. Misschien is niet alle front-end code aangeleverd (bijv. componenten voor TitleField, TagField?), gezien de checklist refereert aan dergelijke componenten. Mogelijk is de UI nog in ontwikkeling of staat in een privé repository. *Benodigd bewijs:* Up-to-date frontend code of een toelichting van het team over de huidige frontend status. Dit auditrapport gaat er deels van uit dat de backend de belangrijkste focus was en de frontend minimaal functioneel is.
- **Aanname:** Het project zal op Firebase (of vergelijkbaar) draaien voor prod. De .firebaserc duidt op één project ID voor zowel default als staging, wat ongebruikelijk is. **Onzekerheid:** Is er wel een apart productieproject? Misschien is “staging” hier abusievelijk gelijk aan default. *Benodigd:* Deploy-scripts of Firebase projectlijst om te zien of men intern toch wisselt. Het is cruciaal om te weten of de huidige Firestore en Functions al in een testomgeving draaien en hoe die zich verhouden tot een toekomstige productieomgeving.
- **Onzekerheid:** Hoe wordt omgegaan met *wisselende kosten* van OpenAI? De credit-calculatie is gebaseerd op GPT-4 pricing anno nu. Als OpenAI tarieven wijzigen of er een andere modelkeuze komt, is het onduidelijk of dit dynamisch aangepast wordt. De code heeft een functie `estimateCost(model, tokens)` – we veronderstellen dat die up-to-date is met GPT-4 $0.03/1k prompt tokens etc. *Benodigd:* Confirmatie van tariefgebruik in code (in `budgetGuard.js`) en plan hoe dit onderhouden wordt.
- **Aanname:** De security van de Firebase backend (Firestore) vertrouwt sterk op de Admin SDK, wat goed is, maar dat betekent ook dat alle writes vanuit functions doorlopen ondanks security rules. We gaan ervan uit dat alle client-communicatie uitsluitend via de provided Cloud Functions loopt en niet direct op Firestore (behalve misschien voor realtime updates?). **Onzekerheid:** Zijn er plekken waar de frontend direct Firestore leest of schrijft (bijv. to show logs or user credits)? Zo ja, dan moeten de Firestore.rules die scenario’s dekken (nu zijn ze vooral gericht op function writes). *Benodigd:* Code of info of de frontend een `firebaseClient.ts` gebruikt (genoemd in checklist) en welke rechten die nodig heeft.
- **Onzekerheid:** In de logs zien we melding van *“testuser123 verplicht voor logging”*. Dit suggereert dat in non-auth scenario’s men `uid = testuser123` gebruikt. In code troffen we “unknown”. Misschien is dit veranderd in de http_wrapper (`http_generateFromDumpCore.js`) die testuser afdwingt. *Benodigd:* Inzage in die wrapper file om te zien of daarin `'testuser123'` staat. Dit is relevant: een vaste test UID in productie zou uiteraard fout zijn (zou immers ieders gebruik bundelen). We gaan ervan uit dat “unknown” in code nog vervangen moet worden door echte uid of een nette guest-handle.
- **Aanname:** De huidige testcoverage (84%) is acceptabel gezien een soft-fail approach, en men zal nog doorpakken om de resterende tests te laten slagen (32/38 nu). **Onzekerheid:** Welke tests falen er nu (15.8% fails)? Betreft dit randgevallen die voor productie niet kritisch zijn, of duidt dit op incomplete functionaliteit (bv. een validator edge-case)? *Benodigd:* Testrapport of lijst van falende tests om te bepalen of hier nog fixes voor nodig zijn. Idealiter zijn alle tests groen bij oplevering.
- **Onzekerheid:** Load/performance onder echte omstandigheden. Er is aangenomen dat één function instance meerdere requests sequentieel aankan en cold starts binnen redelijke marges vallen. Dit is nog niet in cijfers onderbouwd. *Benodigd:* Eventueel een JMeter/Gatling test tegen de deployed function, om aan te nemen dat b.v. 10 gelijktijdige gebruikers nog sub-2s respons krijgen. Nu is dat niet gedaan, dus prestatie-aannames blijven onzeker.

Elk van deze onzekerheden kan worden weggenomen door gericht bewijs of tests, wat we aanbevelen vóór definitieve livegang. Het merendeel betreft echter configureer-/bevestigingszaken en **niet** fundamentele codeproblemen. In sum, de bekende unknowns zijn beheersbaar met beperkte aanvullende verificatie.